{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*Python Modules*","metadata":{"_cell_guid":"b4eb5ad5-03ba-4fc4-b417-451e30a01fd1","_uuid":"be3002e45fc687fc33e7c7ae9d869ac7ee926b1a"}},{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets,models,transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport cv2\nimport numpy as np\nfrom skimage.morphology import (erosion, dilation, opening, closing, white_tophat,disk)\n\nplt.ion()  \n\nuse_gpu = torch.cuda.is_available()\n","metadata":{"_cell_guid":"0e05b5f8-fc51-404d-a9d2-5197aa283b73","_uuid":"76fd0ec2a5eb7fbe49b51147eabbd109c61279c0","execution":{"iopub.status.busy":"2021-11-18T09:02:13.183347Z","iopub.execute_input":"2021-11-18T09:02:13.184045Z","iopub.status.idle":"2021-11-18T09:02:13.20949Z","shell.execute_reply.started":"2021-11-18T09:02:13.183983Z","shell.execute_reply":"2021-11-18T09:02:13.208749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n    \"\"\"Custom dataset that includes image file paths. Extends\n    torchvision.datasets.ImageFolder\n    \"\"\"\n\n    # override the __getitem__ method. this is the method that dataloader calls\n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:02:13.210395Z","iopub.execute_input":"2021-11-18T09:02:13.210723Z","iopub.status.idle":"2021-11-18T09:02:13.22277Z","shell.execute_reply.started":"2021-11-18T09:02:13.210663Z","shell.execute_reply":"2021-11-18T09:02:13.222053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing image","metadata":{}},{"cell_type":"code","source":"def opening(img):\n    kernel = np.ones((5, 5), np.uint8)\n    img_erosion = cv2.erode(img, kernel, iterations=1)\n    img_dilation = cv2.dilate(img_erosion, kernel, iterations=1)\n    return img_dilation\ndef denoise(img):\n    #denoise_img = cv2.medianBlur(img,9)\n    denoise_img = cv2.bilateralFilter(img, 15, 75, 75)\n    return denoise_img","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:02:13.223699Z","iopub.execute_input":"2021-11-18T09:02:13.223902Z","iopub.status.idle":"2021-11-18T09:02:13.235281Z","shell.execute_reply.started":"2021-11-18T09:02:13.223865Z","shell.execute_reply":"2021-11-18T09:02:13.234386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow)/255\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131*(contrast + 127)/(127*(131-contrast))\n        alpha_c = f\n        gamma_c = 127*(1-f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:02:13.236492Z","iopub.execute_input":"2021-11-18T09:02:13.23691Z","iopub.status.idle":"2021-11-18T09:02:13.264452Z","shell.execute_reply.started":"2021-11-18T09:02:13.236768Z","shell.execute_reply":"2021-11-18T09:02:13.263577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import cm\ndef preprocessing(img):\n    return Image.fromarray(np.uint8(apply_brightness_contrast(opening(denoise(np.array(img))),0,16)))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:02:13.26557Z","iopub.execute_input":"2021-11-18T09:02:13.266077Z","iopub.status.idle":"2021-11-18T09:02:13.27647Z","shell.execute_reply.started":"2021-11-18T09:02:13.266001Z","shell.execute_reply":"2021-11-18T09:02:13.275763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load train and test data","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/data-chamber/DATA_CHAMBER_2021/'\nTRAIN = 'train'\nTEST = 'test'\n# VGG-16 Takes 224x224 images as input, so we resize all of them\n\ndata_transforms = {\n    TRAIN: transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(),\n        preprocessing,\n        transforms.ToTensor()]),\n    TEST: transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        preprocessing,\n        transforms.ToTensor(),\n    ])\n}\n\nimage_datasets = {\n    x: ImageFolderWithPaths(\n        os.path.join(data_dir, x), \n        transform=data_transforms[x]\n    )\n    for x in [TRAIN,TEST]\n}\n\ndataloaders = {\n    TRAIN: torch.utils.data.DataLoader(\n        image_datasets[TRAIN], batch_size=32,\n        shuffle=True, num_workers=4\n    ),\n    TEST: torch.utils.data.DataLoader(\n        image_datasets[TEST], batch_size=32,\n        shuffle=False, num_workers=4\n    )\n    \n}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN,  TEST]}\n\nfor x in [TRAIN, TEST]:\n    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n    \nprint(\"Classes: \")\nclass_names = image_datasets[TRAIN].classes\nprint(image_datasets[TRAIN].classes)","metadata":{"_cell_guid":"e9d7ef88-fdbd-4b73-b64f-70294976d238","id":"xvsy0IR4wheJ","executionInfo":{"elapsed":1074,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525007461873,"user_tz":-120,"status":"ok"},"_uuid":"83371f19c7f1e261bb0f9cc71f7a265c37a4c16a","outputId":"bb02efaa-518c-4342-d6e5-7275a7d7fdd5","execution":{"iopub.status.busy":"2021-11-18T09:02:13.278165Z","iopub.execute_input":"2021-11-18T09:02:13.278411Z","iopub.status.idle":"2021-11-18T09:02:14.016279Z","shell.execute_reply.started":"2021-11-18T09:02:13.278366Z","shell.execute_reply":"2021-11-18T09:02:14.015325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show images from a batch","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    # plt.figure(figsize=(10, 10))\n    plt.axis('off')\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n\ndef show_databatch(inputs, classes):\n    out = torchvision.utils.make_grid(inputs)\n    imshow(out, title=[class_names[x] for x in classes])\n\n# Get a batch of training data\ninputs, classes,_ = next(iter(dataloaders[TRAIN]))\nshow_databatch(inputs, classes)","metadata":{"_cell_guid":"fd84399d-83f9-4af7-8767-fe1d32856493","id":"rphPgOQewheQ","executionInfo":{"elapsed":1443,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525007467056,"user_tz":-120,"status":"ok"},"_uuid":"48e7f7c02cab559638af532e98d371ebd8c89bfa","outputId":"0bec4c14-9968-4119-bb75-f896ddc21ebd","execution":{"iopub.status.busy":"2021-11-18T09:02:14.017905Z","iopub.execute_input":"2021-11-18T09:02:14.01858Z","iopub.status.idle":"2021-11-18T09:02:17.855409Z","shell.execute_reply.started":"2021-11-18T09:02:14.018511Z","shell.execute_reply":"2021-11-18T09:02:17.85455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.__version__","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:02:17.857244Z","iopub.execute_input":"2021-11-18T09:02:17.857783Z","iopub.status.idle":"2021-11-18T09:02:17.871862Z","shell.execute_reply.started":"2021-11-18T09:02:17.857731Z","shell.execute_reply":"2021-11-18T09:02:17.869951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(vgg, num_images=6):\n    was_training = vgg.training\n    \n    # Set model for evaluation\n    vgg.train(False)\n    vgg.eval() \n    \n    images_so_far = 0\n\n    for i, data in enumerate(dataloaders[TEST]):\n        inputs, labels,_ = data\n        size = inputs.size()[0]\n        \n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n        \n        outputs = vgg(inputs)\n        \n        _, preds = torch.max(outputs.data, 1)\n        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n        \n        print(\"Ground truth:\")\n        show_databatch(inputs.data.cpu(), labels.data.cpu())\n        print(\"Prediction:\")\n        show_databatch(inputs.data.cpu(), predicted_labels)\n        \n        del inputs, labels, outputs, preds, predicted_labels\n        torch.cuda.empty_cache()\n        \n        images_so_far += size\n        if images_so_far >= num_images:\n            break\n        \n    vgg.train(mode=was_training) # Revert model back to original training state","metadata":{"_cell_guid":"5e6e0c3f-19bd-4034-b408-eeffb9746275","id":"WXgC3SYkwheT","_uuid":"d7785c091b61ab0ddff8556c06bafc5f16037aa4","execution":{"iopub.status.busy":"2021-11-18T09:02:17.8739Z","iopub.execute_input":"2021-11-18T09:02:17.8776Z","iopub.status.idle":"2021-11-18T09:02:18.131621Z","shell.execute_reply.started":"2021-11-18T09:02:17.8775Z","shell.execute_reply":"2021-11-18T09:02:18.130164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate func","metadata":{}},{"cell_type":"markdown","source":"This helper function will give us the accuracy of our model on the test set.","metadata":{"_cell_guid":"d3ad92fa-f55c-4542-ba7a-55f2dad9cf97","_uuid":"d4aa323ffa73c1af0425163096f06ae548f39a2b"}},{"cell_type":"code","source":"\ndef eval_model(vgg, criterion):\n    y_true = []\n    y_pred = []\n    vid_id = []\n    since = time.time()\n    avg_loss = 0\n    avg_acc = 0\n    loss_test = 0\n    acc_test = 0\n    \n    test_batches = len(dataloaders[TEST])\n    print(\"Evaluating model\")\n    print('-' * 10)\n    \n    for i, data in enumerate(dataloaders[TEST]):\n        if i % 100 == 0:\n            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n        vgg.train(False)\n        vgg.eval()\n        inputs, labels, fname = data\n        for f in fname:\n            vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n        y_true = y_true + labels.tolist()\n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n        else:\n            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n\n        outputs = vgg(inputs)\n\n        _, preds = torch.max(outputs.data, 1)\n        loss = criterion(outputs, labels)\n        #print(preds)\n        y_pred = y_pred + preds.tolist()\n        \n        loss_test += loss.data[0]\n        acc_test += torch.sum(preds == labels.data)\n\n        del inputs, labels, outputs, preds\n        torch.cuda.empty_cache()\n        \n    avg_loss = loss_test / dataset_sizes[TEST]\n    avg_acc = acc_test / dataset_sizes[TEST]\n    \n    elapsed_time = time.time() - since\n    print()\n    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n    print('-' * 10)\n    return y_true,y_pred,vid_id","metadata":{"_cell_guid":"1b74302a-9418-4472-970f-76591d00cecb","_uuid":"6d1b1cd49e177152940d8f667b9fa5e2e1c5e360","execution":{"iopub.status.busy":"2021-11-18T09:02:18.135122Z","iopub.execute_input":"2021-11-18T09:02:18.135535Z","iopub.status.idle":"2021-11-18T09:02:18.71783Z","shell.execute_reply.started":"2021-11-18T09:02:18.135455Z","shell.execute_reply":"2021-11-18T09:02:18.716566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"vgg16 = models.vgg19_bn()\nvgg16.load_state_dict(torch.load(\"../input/vgg19bn/vgg19_bn.pth\"))\nprint(vgg16.classifier[6].out_features) # 1000 \n\n\n# Freeze training for all layers\n# for param in vgg16.features.parameters():\n#     param.require_grad = False\n\n# Newly created modules have require_grad=True by default\nnum_features = vgg16.classifier[6].in_features\nfeatures = list(vgg16.classifier.children())[:-1] # Remove last layer\nfeatures.extend([nn.Linear(num_features, len(class_names))]) # Add our layer with 4 outputs\nvgg16.classifier = nn.Sequential(*features) # Replace the model classifier","metadata":{"_cell_guid":"4be764f7-24ff-4611-8fc6-31b87e3ed171","id":"SjHLMTldwheY","executionInfo":{"elapsed":2623,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525007474565,"user_tz":-120,"status":"ok"},"_uuid":"480b7181f00142865d3e971c799dd42bc9d1f7e5","outputId":"4c40caae-9d25-47e5-fe17-a4f3f944487e","execution":{"iopub.status.busy":"2021-11-18T09:02:18.719361Z","iopub.execute_input":"2021-11-18T09:02:18.719753Z","iopub.status.idle":"2021-11-18T09:02:33.767773Z","shell.execute_reply.started":"2021-11-18T09:02:18.719651Z","shell.execute_reply":"2021-11-18T09:02:33.766497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output above is the summary of our model. Notice how the last layer has 4 output features as we specified. ","metadata":{"_cell_guid":"731d8833-c6d1-4cba-996c-882ccf547f95","_uuid":"cc4ce91edbd602335e92505a269de62e077385ec"}},{"cell_type":"code","source":"# If you want to train the model for more than 10 epochs, set this to True after the first run\nresume_training = False\n\nif resume_training:\n    print(\"Loading pretrained model..\")\n    vgg16.load_state_dict(torch.load('../input/vgg19bnechocardiogrampretrained/VGG19_echocardiogram.pt'))\n    print(\"Loaded!\")","metadata":{"_cell_guid":"f45bda67-096e-4de9-a801-98742c34207c","id":"Xuaq38UOwhec","_uuid":"bd59ea5c500e55b3ae4bd9cdfeae01bd50818668","execution":{"iopub.status.busy":"2021-11-18T09:02:33.769066Z","iopub.execute_input":"2021-11-18T09:02:33.769355Z","iopub.status.idle":"2021-11-18T09:02:33.775168Z","shell.execute_reply.started":"2021-11-18T09:02:33.769307Z","shell.execute_reply":"2021-11-18T09:02:33.774484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_gpu:\n    vgg16.cuda() #.cuda() will move everything to the GPU side\n    \ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(vgg16.parameters(), lr=0.01, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)","metadata":{"_cell_guid":"df23921b-f26e-496a-9a71-cdf2a9daa34e","id":"HTJWo25nwhef","_uuid":"45d872d00fcfe93de8938b8741b4526af971c62b","execution":{"iopub.status.busy":"2021-11-18T09:02:33.776477Z","iopub.execute_input":"2021-11-18T09:02:33.776968Z","iopub.status.idle":"2021-11-18T09:02:33.928101Z","shell.execute_reply.started":"2021-11-18T09:02:33.776916Z","shell.execute_reply":"2021-11-18T09:02:33.92751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation and visualization (before training)\n\nLet's see how our model performs before any training","metadata":{"_cell_guid":"996330eb-394c-4916-a924-8d77bc2ffb5b","_uuid":"5ced4fda7b1a2f175f8795eb5b4d8a1a66c76497","id":"MuVPA5gkwhen"}},{"cell_type":"code","source":"print(\"Test before training\")\neval_model(vgg16, criterion)\nprint('')","metadata":{"_cell_guid":"f7aec745-2087-4f60-987d-a34a995fd6a9","id":"jSa-X3XVwheo","executionInfo":{"elapsed":1986,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525007488210,"user_tz":-120,"status":"ok"},"_uuid":"7732406aae91a82348fcb830a5ff5785d22526fb","outputId":"d6f338d4-5379-4fe8-aaec-cc8141b7cbb5","execution":{"iopub.status.busy":"2021-11-18T09:02:33.929272Z","iopub.execute_input":"2021-11-18T09:02:33.929581Z","iopub.status.idle":"2021-11-18T09:03:12.89657Z","shell.execute_reply.started":"2021-11-18T09:02:33.929518Z","shell.execute_reply":"2021-11-18T09:03:12.895323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize_model(vgg16) #test before training","metadata":{"_cell_guid":"dabed264-9a90-4888-ad3c-65924ad9c80d","_uuid":"eff4aa2d97fd5443195ae2a2cd43c5f73e6775a3","execution":{"iopub.status.busy":"2021-11-18T09:03:12.898375Z","iopub.execute_input":"2021-11-18T09:03:12.898706Z","iopub.status.idle":"2021-11-18T09:03:12.905035Z","shell.execute_reply.started":"2021-11-18T09:03:12.898651Z","shell.execute_reply":"2021-11-18T09:03:12.904352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not really great results. Let's see if it can do better after training ","metadata":{"_cell_guid":"e1d7a980-d27f-4637-a04e-abfbe67464fb","_uuid":"464dc207138f6042bf8b9b1e33d5c792c00b8dac"}},{"cell_type":"markdown","source":"## Training\n\n\n\nFor every epoch we iterate over all the training batches, compute the loss , and adjust the network weights with `loss.backward()` and `optimizer.step()`. \nThen we evaluate the performance over the validaton set. At the end of every epoch we print the network progress (loss and accuracy). \nThe accuracy will tell us how many predictions were correct.\n\nAs we said before, transfer learning can work on smaller dataset too, so for every epoch we only iterate over half the trainig dataset (worth noting that it won't exactly be half of it over the entire training, as the data is shuffled, but it will almost certainly be a subset) ","metadata":{"_cell_guid":"46ffdcaf-049a-4dbe-ba6d-b25ccc4ff448","_uuid":"d157eb6d3f1f94af2a369bff6e3e5277482ea6c2","id":"xDUpsi7cwhes"}},{"cell_type":"code","source":"def train_model(vgg, criterion, optimizer, scheduler, num_epochs=5):\n    since = time.time()\n    best_model_wts = copy.deepcopy(vgg.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(dataloaders[TRAIN])\n    #val_batches = len(dataloaders[VAL])\n    loss_values = []\n    acc_values = []\n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch+1, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_val = 0\n        acc_train = 0\n#         acc_val = 0\n        \n        vgg.train(True)\n        \n        for i, data in enumerate(dataloaders[TRAIN]):\n            \n            print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n                \n            \n                \n            inputs, labels,_= data\n            \n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            #Sets the gradients of all optimized torch.Tensor s to zero.\n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            #computes dloss/dw for every parameter w which has requires_grad=True.\n            #These are accumulated into w.grad for every parameter w\n            loss.backward()\n            \n            #updates the value of w using the gradient w.grad\n            optimizer.step()\n            \n            loss_train += loss.data[0]\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        avg_loss = loss_train  / dataset_sizes[TRAIN]\n        avg_acc = acc_train  / dataset_sizes[TRAIN]\n        loss_values.append(avg_loss)\n        acc_values.append(avg_acc)\n        vgg.train(False)\n        vgg.eval()\n            \n\n        \n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n\n        print('-' * 10)\n        print()\n        \n        if avg_acc > best_acc:\n            best_acc = avg_acc\n            best_model_wts = copy.deepcopy(vgg.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    vgg.load_state_dict(best_model_wts)\n    return vgg,acc_values,loss_values","metadata":{"_cell_guid":"8f6936eb-ae6f-44ee-90a9-c7f817ba6eda","id":"lHkiBU5fwhet","_uuid":"abe5dc35b31e7971e7d63637866132f89e7d011d","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-18T09:03:12.906384Z","iopub.execute_input":"2021-11-18T09:03:12.908567Z","iopub.status.idle":"2021-11-18T09:03:13.161395Z","shell.execute_reply.started":"2021-11-18T09:03:12.908513Z","shell.execute_reply":"2021-11-18T09:03:13.160731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16,acc,loss = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)\ntorch.save(vgg16.state_dict(),'VGG19_echocardiogram.pt')","metadata":{"_cell_guid":"53eeb478-e106-49be-9682-0173e76640f8","id":"r1-I_IUUwhew","executionInfo":{"elapsed":304,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525023518627,"user_tz":-120,"status":"ok"},"_uuid":"a0ddf54b1c45b7c61724cbe1e74ca0628f8b1d8e","outputId":"b764e48a-00fd-4eb5-f592-f4386a875ed1","execution":{"iopub.status.busy":"2021-11-18T09:03:13.162718Z","iopub.execute_input":"2021-11-18T09:03:13.16314Z","iopub.status.idle":"2021-11-18T09:32:33.931831Z","shell.execute_reply.started":"2021-11-18T09:03:13.163083Z","shell.execute_reply":"2021-11-18T09:32:33.931039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model evaluation and visualization (after training)\n\nLet's evaluate our model again after 10 epochs of training","metadata":{"_cell_guid":"f9276b6e-2984-469b-820e-9eb1f7eeced5","_uuid":"7898a0245f8b5c5961945c4a591dfea2ea72ea94"}},{"cell_type":"code","source":"y_true,y_pred,vid_code = eval_model(vgg16, criterion)","metadata":{"_cell_guid":"f8d905fe-9f7f-484b-b926-9931ca887e34","_uuid":"2803b24b7002a785833d300413e3bd8891f398f9","execution":{"iopub.status.busy":"2021-11-18T09:32:33.933412Z","iopub.execute_input":"2021-11-18T09:32:33.933751Z","iopub.status.idle":"2021-11-18T09:33:12.553744Z","shell.execute_reply.started":"2021-11-18T09:32:33.933697Z","shell.execute_reply":"2021-11-18T09:33:12.552683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize our model ._.","metadata":{}},{"cell_type":"code","source":"visualize_model(vgg16, num_images=32)","metadata":{"_cell_guid":"c3f7f06c-97fe-4f8e-8b47-f512d4989ecb","id":"hGLvyjZ2whe0","executionInfo":{"elapsed":4437,"user":{"displayName":"Carlo Alberto","userId":"107843268563316278814","photoUrl":"//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg"},"timestamp":1525025142751,"user_tz":-120,"status":"ok"},"_uuid":"4f2ed1c58098075949f93eadc7ba3b5786c7b307","outputId":"497f6621-ee2c-43a5-9b54-917bbbe9b22c","execution":{"iopub.status.busy":"2021-11-18T09:33:12.600269Z","iopub.execute_input":"2021-11-18T09:33:12.602329Z","iopub.status.idle":"2021-11-18T09:33:17.514398Z","shell.execute_reply.started":"2021-11-18T09:33:12.602275Z","shell.execute_reply":"2021-11-18T09:33:17.513586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report\nprint(classification_report(y_true,y_pred))\nprint(accuracy_score(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.516107Z","iopub.execute_input":"2021-11-18T09:33:17.518989Z","iopub.status.idle":"2021-11-18T09:33:17.699332Z","shell.execute_reply.started":"2021-11-18T09:33:17.518788Z","shell.execute_reply":"2021-11-18T09:33:17.698524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The accuracy score seem to be good \n\nHope you found this useful! ","metadata":{"_cell_guid":"7885babe-9858-4199-b6cc-df13f507c91b","_uuid":"c83e276974d07d618bea5a0e1f603b9fd9b21193"}},{"cell_type":"markdown","source":"# Let check out our test data\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport glob\n\n\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_code)),columns =['y_true','y_pred','vid_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.703119Z","iopub.execute_input":"2021-11-18T09:33:17.705024Z","iopub.status.idle":"2021-11-18T09:33:17.790388Z","shell.execute_reply.started":"2021-11-18T09:33:17.703365Z","shell.execute_reply":"2021-11-18T09:33:17.789549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.794324Z","iopub.execute_input":"2021-11-18T09:33:17.794634Z","iopub.status.idle":"2021-11-18T09:33:17.845986Z","shell.execute_reply.started":"2021-11-18T09:33:17.794576Z","shell.execute_reply":"2021-11-18T09:33:17.845251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statistics import mode\nvid_list = list(set(df['vid_id'].values))\n#df.groupby(['vid_id'])\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.849648Z","iopub.execute_input":"2021-11-18T09:33:17.851536Z","iopub.status.idle":"2021-11-18T09:33:17.874247Z","shell.execute_reply.started":"2021-11-18T09:33:17.849879Z","shell.execute_reply":"2021-11-18T09:33:17.873335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(vid_list)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.876697Z","iopub.execute_input":"2021-11-18T09:33:17.878924Z","iopub.status.idle":"2021-11-18T09:33:17.88939Z","shell.execute_reply.started":"2021-11-18T09:33:17.878866Z","shell.execute_reply":"2021-11-18T09:33:17.887097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = []\ny_pred = []\nfor vid in vid_list:\n    #print(vid)\n    tmp_df = df[df['vid_id']==vid]\n    #print(len(tmp_df))\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)\n    #print(vid_label,\"\\n\",vid_pred)\n    \n    #print('vid: {} label: {} pred: {}'.format(vid,vid_label,vid_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.893687Z","iopub.execute_input":"2021-11-18T09:33:17.894741Z","iopub.status.idle":"2021-11-18T09:33:17.994125Z","shell.execute_reply.started":"2021-11-18T09:33:17.894689Z","shell.execute_reply":"2021-11-18T09:33:17.993458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:17.995127Z","iopub.execute_input":"2021-11-18T09:33:17.995387Z","iopub.status.idle":"2021-11-18T09:33:18.003365Z","shell.execute_reply.started":"2021-11-18T09:33:17.995343Z","shell.execute_reply":"2021-11-18T09:33:18.002289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot training history","metadata":{}},{"cell_type":"code","source":"def plot_history(history,loss,acc): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(loss, 'r', label=\"loss\")\n    ax1.grid(True)\n    ax1.set_xlabel('epoch')\n    ax1.set_ylabel('loss', color='r')\n    ax1.legend(loc=\"lower right\", fontsize=9)    \n    ax1.tick_params('y', colors='r')\n\n    ax2 = ax1.twinx()\n    ax2.plot(acc, 'g', label=\"acc\")\n    ax2.legend(loc=\"upper right\", fontsize=9)\n    ax2.set_ylabel('accuracy', color='g')        \n    ax2.tick_params('y', colors='g')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:18.010323Z","iopub.execute_input":"2021-11-18T09:33:18.010754Z","iopub.status.idle":"2021-11-18T09:33:18.075896Z","shell.execute_reply.started":"2021-11-18T09:33:18.010697Z","shell.execute_reply":"2021-11-18T09:33:18.073804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(vgg16,loss,acc)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T09:33:18.081501Z","iopub.execute_input":"2021-11-18T09:33:18.083913Z","iopub.status.idle":"2021-11-18T09:33:18.814973Z","shell.execute_reply.started":"2021-11-18T09:33:18.083839Z","shell.execute_reply":"2021-11-18T09:33:18.813654Z"},"trusted":true},"execution_count":null,"outputs":[]}]}