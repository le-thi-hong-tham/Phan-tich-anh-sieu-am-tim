{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\nfrom collections import OrderedDict\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport sklearn.svm\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import classification_report, confusion_matrix  \nfrom collections import Counter\nimport random\n\n\nplt.ion()  \n\nuse_gpu = torch.cuda.is_available()\n","metadata":{"_uuid":"725dbdab-0b4d-44e4-b8df-6f7c7cb69ab2","_cell_guid":"ef9a6327-3d93-4b8d-bbe7-c3e87753ddf1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:40.147111Z","iopub.execute_input":"2021-11-28T09:36:40.147574Z","iopub.status.idle":"2021-11-28T09:36:40.155796Z","shell.execute_reply.started":"2021-11-28T09:36:40.147530Z","shell.execute_reply":"2021-11-28T09:36:40.154797Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ImageFolderWithPaths(datasets.ImageFolder):\n    \"\"\"Custom dataset that includes image file paths. Extends\n    torchvision.datasets.ImageFolder\n    \"\"\"\n\n    # override the __getitem__ method. this is the method that dataloader calls\n    def __getitem__(self, index):\n        # this is what ImageFolder normally returns \n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        # the image file path\n        path = self.imgs[index][0]\n        # make a new tuple that includes original and the path\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path","metadata":{"_uuid":"c631be41-9512-4071-a841-a35dde5c1c96","_cell_guid":"fff91580-68a8-4340-a6df-cf5eb2f69b4e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:40.157816Z","iopub.execute_input":"2021-11-28T09:36:40.158092Z","iopub.status.idle":"2021-11-28T09:36:40.167028Z","shell.execute_reply.started":"2021-11-28T09:36:40.158033Z","shell.execute_reply":"2021-11-28T09:36:40.166302Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/data-chamber/DATA_CHAMBER_2021'\ntrain_dir = data_dir + '/train'\ntest_dir = data_dir + '/test'\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.Grayscale(3),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor()]),\n    'test': transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n    ])\n}\n\nimage_datasets = {\n    x: ImageFolderWithPaths(\n        os.path.join(data_dir, x), \n        transform=data_transforms[x]\n    )\n    for x in ['train', 'test']\n}\n\ndataloaders = {\n    x: torch.utils.data.DataLoader(\n        image_datasets[x], batch_size=8,\n        shuffle=True, num_workers=2\n    )\n    for x in ['train', 'test']\n}\npathloaders = {\n    x: torch.utils.data.DataLoader(\n        image_datasets[x].imgs, batch_size=8,\n        shuffle=True, num_workers=2\n    )\n    for x in ['train', 'test']\n}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train',  'test']}\n\n#Check cuda\ndevice= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n","metadata":{"_uuid":"4820b273-cefe-44a0-bfc1-65acb1cc5c8e","_cell_guid":"f8e1342c-e248-444d-b88e-fabe66c29397","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:40.167961Z","iopub.execute_input":"2021-11-28T09:36:40.168172Z","iopub.status.idle":"2021-11-28T09:36:41.259349Z","shell.execute_reply.started":"2021-11-28T09:36:40.168148Z","shell.execute_reply":"2021-11-28T09:36:41.258624Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"for x in ['train', 'test']:\n    print(\"Loaded {} images in {}\".format(dataset_sizes[x], x))\n    \nprint(\"Classes: \")\n\nlabel = image_datasets['train'].classes\nprint(image_datasets['train'].classes)","metadata":{"_uuid":"57b68623-ce0e-42bf-a567-907370b094e6","_cell_guid":"e51c2910-f722-4a7c-9956-b0dd8e169b25","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.261499Z","iopub.execute_input":"2021-11-28T09:36:41.261769Z","iopub.status.idle":"2021-11-28T09:36:41.267462Z","shell.execute_reply.started":"2021-11-28T09:36:41.261735Z","shell.execute_reply":"2021-11-28T09:36:41.266730Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n    \ndef show_databatch(inputs, classes):\n    out = torchvision.utils.make_grid(inputs)\n    imshow(out, title=[label[x] for x in classes])\n\n\n# Get a batch of training data\ninputs, classes,_ = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[label[x] for x in classes])","metadata":{"_uuid":"66e63533-147e-4b8b-9ef3-e17afda10bbf","_cell_guid":"5d30823b-60e1-4c24-911a-d646c8ee656f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.268967Z","iopub.execute_input":"2021-11-28T09:36:41.269504Z","iopub.status.idle":"2021-11-28T09:36:41.885172Z","shell.execute_reply.started":"2021-11-28T09:36:41.269467Z","shell.execute_reply":"2021-11-28T09:36:41.884474Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"torch.__version__","metadata":{"_uuid":"2bd1f2d4-f765-4056-a1bc-922e9eafcfa9","_cell_guid":"2377ac7f-bcad-44b3-9c2c-39be5793c2ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.888246Z","iopub.execute_input":"2021-11-28T09:36:41.888469Z","iopub.status.idle":"2021-11-28T09:36:41.894531Z","shell.execute_reply.started":"2021-11-28T09:36:41.888442Z","shell.execute_reply":"2021-11-28T09:36:41.893755Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    \n    # Set model for evaluation\n    model.train(False)\n    model.eval() \n    \n    images_so_far = 0\n\n    for i, data in enumerate(dataloaders['test']):\n        inputs, labels,_ = data\n        size = inputs.size()[0]\n        \n        if use_gpu:\n            with torch.no_grad():\n                inputs, labels = inputs.cuda(), labels.cuda()\n        else:\n            with torch.no_grad():\n                inputs, labels = inputs, labels\n        \n        outputs = model(inputs)\n        \n        _, preds = torch.max(outputs.data, 1)\n        predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n        \n        print(\"Ground truth:\")\n        show_databatch(inputs.data.cpu(), labels.data.cpu())\n        print(\"Prediction:\")\n        show_databatch(inputs.data.cpu(), predicted_labels)\n        \n        del inputs, labels, outputs, preds, predicted_labels\n        torch.cuda.empty_cache()\n        \n        images_so_far += size\n        if images_so_far >= num_images:\n            break\n        \n    model.train(mode=was_training)","metadata":{"_uuid":"2f3de6e6-d194-4632-af8f-93a626ba6753","_cell_guid":"c11f1bd4-a0e9-4c35-ab65-790acfc3dc1a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.895895Z","iopub.execute_input":"2021-11-28T09:36:41.896293Z","iopub.status.idle":"2021-11-28T09:36:41.907022Z","shell.execute_reply.started":"2021-11-28T09:36:41.896257Z","shell.execute_reply":"2021-11-28T09:36:41.906249Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, criterion):\n    y_true = []\n    y_pred = []\n    vid_id = []\n    since = time.time()\n    avg_loss = 0\n    avg_acc = 0\n    loss_test = 0\n    acc_test = 0\n    \n    test_batches = len(dataloaders['test'])\n    print(\"Evaluating model\")\n    print('-' * 10)\n    \n    for i, data in enumerate(dataloaders['test']):\n        if i % 100 == 0:\n            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n\n        model.train(False)\n        model.eval()\n        \n        inputs, labels, fname = data\n        \n        for f in fname:\n            vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n        y_true = y_true + labels.tolist()\n        \n        if use_gpu:\n            with torch.no_grad():\n                inputs, labels = inputs.cuda(), labels.cuda()\n        else:\n            with torch.no_grad():\n                inputs, labels = inputs, labels\n\n        outputs = model(inputs)\n\n        _, preds = torch.max(outputs.data, 1)\n        loss = criterion(outputs, labels)\n        #print(preds)\n        y_pred = y_pred + preds.tolist()\n        \n        loss_test += loss.item()\n        acc_test += torch.sum(preds == labels.data)\n\n        del inputs, labels, outputs, preds\n        torch.cuda.empty_cache()\n        \n    avg_loss = loss_test / dataset_sizes['test']\n    avg_acc = acc_test / dataset_sizes['test']\n    \n    elapsed_time = time.time() - since\n    print()\n    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n    print('-' * 10)\n    return y_true,y_pred,vid_id","metadata":{"_uuid":"fe66aa6e-9bb8-4328-9e25-114b4e9277ef","_cell_guid":"f1a7482f-9bd4-431e-a582-67e16618c4c8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.908262Z","iopub.execute_input":"2021-11-28T09:36:41.908635Z","iopub.status.idle":"2021-11-28T09:36:41.921923Z","shell.execute_reply.started":"2021-11-28T09:36:41.908594Z","shell.execute_reply":"2021-11-28T09:36:41.921219Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = models.vgg19_bn()\nmodel.load_state_dict(torch.load(\"../input/vgg19bn/vgg19_bn.pth\"))\nprint(model.classifier[6].out_features) # 1000 \n\n\n# Freeze training for all layers\nfor param in model.features.parameters():\n    param.require_grad = False\n\n# Newly created modules have require_grad=True by default\nnum_features = model.classifier[6].in_features\nfeatures = list(model.classifier.children())[:-1] # Remove last layer\nfeatures.extend([nn.Linear(num_features, len(label))]) # Add our layer with 4 outputs\nmodel.classifier = nn.Sequential(*features) # Replace the model classifier","metadata":{"_uuid":"57c32d34-ae08-4363-88f0-fdec25cd7cf8","_cell_guid":"b196ae9e-2434-4cf6-8c83-d492ef0409e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:41.923006Z","iopub.execute_input":"2021-11-28T09:36:41.923435Z","iopub.status.idle":"2021-11-28T09:36:44.681882Z","shell.execute_reply.started":"2021-11-28T09:36:41.923398Z","shell.execute_reply":"2021-11-28T09:36:44.681122Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# If you want to train the model for more than 2 epochs, set this to True after the first run\nresume_training = False\n\nif resume_training:\n    print(\"Loading pretrained model..\")\n    model.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n    print(\"Loaded!\")\n    \nif use_gpu:\n    model.cuda() #.cuda() will move everything to the GPU side\n    \ncriterion = nn.CrossEntropyLoss()\n\noptimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"_uuid":"98a8a225-4666-4c03-8713-e6276ad549e9","_cell_guid":"4eda27fa-1c23-45ac-b29d-688e3c7ddc84","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:44.684698Z","iopub.execute_input":"2021-11-28T09:36:44.685403Z","iopub.status.idle":"2021-11-28T09:36:44.835338Z","shell.execute_reply.started":"2021-11-28T09:36:44.685364Z","shell.execute_reply":"2021-11-28T09:36:44.834620Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(\"Test before training\")\neval_model(model, criterion)\nprint('')","metadata":{"_uuid":"c37a4cb2-0b45-4b58-9a0c-4869ea5ce3dd","_cell_guid":"6e991c74-5bd2-4ccf-aa5b-0788945718f1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-11-28T09:36:44.836713Z","iopub.execute_input":"2021-11-28T09:36:44.836959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model) #test before training","metadata":{"_uuid":"aeb5e293-e826-4bff-8789-be4267030932","_cell_guid":"a1ff7e58-5aae-48a4-aac3-50a6579ce8e4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(vgg, criterion, optimizer, scheduler, num_epochs=5):\n    since = time.time()\n    best_model_wts = copy.deepcopy(vgg.state_dict())\n    best_acc = 0.0\n    \n    avg_loss = 0\n    avg_acc = 0\n    avg_loss_val = 0\n    avg_acc_val = 0\n    \n    train_batches = len(dataloaders['train'])\n    \n    loss_values = []\n    acc_values = []\n    for epoch in range(num_epochs):\n        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n        print('-' * 10)\n        \n        loss_train = 0\n        loss_val = 0\n        acc_train = 0\n        \n        vgg.train(True)\n        \n        for i, data in enumerate(dataloaders['train']):\n            \n            print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n                \n            \n                \n            inputs, labels,_= data\n            \n            if use_gpu:\n                with torch.no_grad():\n                    inputs, labels = inputs.cuda(), labels.cuda()\n            else:\n                with torch.no_grad():\n                    inputs, labels = inputs, labels\n            \n            optimizer.zero_grad()\n            \n            outputs = vgg(inputs)\n            \n            _, preds = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            loss_train += loss.item()\n            acc_train += torch.sum(preds == labels.data)\n            \n            del inputs, labels, outputs, preds\n            torch.cuda.empty_cache()\n        \n        print()\n        # * 2 as we only used half of the dataset\n        avg_loss = loss_train  / dataset_sizes['train']\n        avg_acc = acc_train  / dataset_sizes['train']\n        loss_values.append(avg_loss)\n        acc_values.append(avg_acc)\n        vgg.train(False)\n        vgg.eval()\n            \n\n        \n        print()\n        print(\"Epoch {} result: \".format(epoch))\n        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n\n        print('-' * 10)\n        print()\n        \n        if avg_acc > best_acc:\n            best_acc = avg_acc\n            best_model_wts = copy.deepcopy(vgg.state_dict())\n        \n    elapsed_time = time.time() - since\n    print()\n    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n    print(\"Best acc: {:.4f}\".format(best_acc))\n    \n    vgg.load_state_dict(best_model_wts)\n    return vgg,acc_values,loss_values","metadata":{"_uuid":"151b22c1-3f3c-4811-8516-43067f8d0644","_cell_guid":"9bc636cc-2f94-4722-b80b-84366fb30112","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,acc,loss = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10)\ntorch.save(model.state_dict(),'VGG19_echocardiogram.pt')","metadata":{"_uuid":"5f62fe99-3dc1-434d-badd-c05fb1fc8cd2","_cell_guid":"fb601c09-a30b-4427-86da-5204a35e3886","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true,y_pred,vid_code = eval_model(model, criterion)","metadata":{"_uuid":"a1688607-d7c6-4e87-bc52-6e22da7d6a24","_cell_guid":"47a218ac-4177-4277-956b-b54d1eacae9e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model, num_images = 24)\n\nplt.ioff()\nplt.show()","metadata":{"_uuid":"fe565932-6214-45bc-8090-b25122796b1e","_cell_guid":"a1d236fd-2823-41f6-9a73-f6407a39a002","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report\nimport pandas as pd\nimport glob\n\n#check data\ndf = pd.DataFrame(list(zip(y_true,y_pred,vid_code)),columns =['y_true','y_pred','video_id'])\ndf.to_csv('df.csv',encoding='utf-8',index=False)\ndf.head(29)","metadata":{"_uuid":"9dc1734e-e855-4175-a21b-dbe197e11ec8","_cell_guid":"9b0e490f-ef75-4f33-8a5b-15b658c93df3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statistics import mode\nvid_list = list(set(df['video_id'].values))\n\ntotal = len(vid_list)\nprint(\"The number of videos is {} \\n\".format(total))\nprint(vid_list)","metadata":{"_uuid":"e91f5b39-29fc-4f45-8ef6-36572c8b0385","_cell_guid":"f8d87d7d-4ec6-4389-8db8-2368bcdd40a6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = []\ny_pred = []\nfor vid in vid_list:\n    #print(vid)\n    tmp_df = df[df['video_id'] == vid]\n    #print(len(tmp_df))\n    vid_pred = tmp_df['y_pred'].mode().values[0]\n    vid_label = tmp_df['y_true'].mode().values[0]\n    y_true.append(vid_label)\n    y_pred.append(vid_pred)","metadata":{"_uuid":"c246b92a-8f9c-47f7-af62-224b3149a9eb","_cell_guid":"f0786ad2-4a32-4a1d-94ef-97ed738b5bb8","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Video prediction results based on voting predicted frame's labels","metadata":{"_uuid":"cb16fc21-95b3-4ec9-b016-4aaee1cb3779","_cell_guid":"c70b91a2-92a5-4f99-a33b-7a67d1aaace9","trusted":true}},{"cell_type":"code","source":"accuracy_score(y_true,y_pred)","metadata":{"_uuid":"1ad1603d-8635-4b36-91ee-4160753b2444","_cell_guid":"d955d05a-5393-48f2-8597-4b6cc7ed3b25","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history,loss,acc): \n    fig, ax1 = plt.subplots()\n    \n    ax1.plot(loss, 'r', label=\"training loss\")\n    ax1.grid(True)\n    ax1.set_xlabel('epoch')\n    ax1.set_ylabel('loss', color='r')\n    ax1.legend(loc=\"best\", fontsize=9)    \n    ax1.tick_params('y', colors='r')\n\n    ax2 = ax1.twinx()\n    ax2.plot(acc, 'g', label=\"training acc\")\n    ax2.legend(loc=\"lower right\", fontsize=9)\n    ax2.set_ylabel('accuracy', color='g')        \n    ax2.tick_params('y', colors='g')\nplot_history(model,loss,acc)","metadata":{"_uuid":"bcba2aad-bc11-4122-b59d-dba9043c8991","_cell_guid":"e156008e-3dbc-4fe0-8eb9-edcb71228b1c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}